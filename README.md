# ğŸ’» Mohd Ibrahim Afridi (Afridi)

**AI/ML Engineer â€¢ Independent Researcher â€¢ Entrepreneur â€¢ AI Safety & Trust**
[ğŸŒ Portfolio](https://mohdibrahimai.github.io/portfolio-/) Â· [ğŸ“§ Email](mailto:mohdibrahimafridi.ai@gmail.com) Â· [ğŸ’¼ LinkedIn](https://www.linkedin.com/in/mohd-ibrahim-afridi-381b12381) Â· [ğŸ™ GitHub](https://github.com/mohdibrahimai)

---

## ğŸš€ About Me

Hi, Iâ€™m Afridi â€” an AI/ML engineer and independent researcher obsessed with building **verifiable, trustworthy, safe AI systems**.

* ğŸ§  Founder & CTO at **XCL3NT**, an AI-first commerce brand
* ğŸ§ª Research behind **Dynamic Chainâ€‘ofâ€‘Thought Reward Models (Dâ€‘CoT)** â€” [Read Dâ€‘CoT](https://zenodo.org/records/16554886)
* ğŸ›¡ï¸ Focus: **AI Safety & Trust** â€” evidence, evaluation, safeguards by default
* ğŸŒ Remoteâ€‘ready; open to relocation (US/EU/NZ/SEA)

> *Mission: Make AI safer, more transparent, and actually helpful to humanity.* ğŸŒ±

---

## ğŸ§ª Research Focus

* **AI Safety & Trust:** principled safeguards, abstain/route, redâ€‘team â†’ verify
* **Evidenceâ€‘Bound QA:** answers backed by citations + verification
* **Model Behavior:** failure modes, freshness, calibration, cost tradeâ€‘offs
* **Eval Frameworks:** metrics, CI gates, nightly reports
* **Humanâ€‘Data Pipelines:** collection â†’ curation â†’ evals at scale

---

## ğŸ› ï¸ Selected Projects (renamed for clarity)

> Display names reflect the new branding; links point to current repositories. Once repo slugs are renamed, just update the URLs.

| Project (New Name)                                                                                                | What it Does                                                                                        | Tech                           |
| ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------ |
| **Evidenceâ€‘Bound Answering System** ([old: ARGOS](https://github.com/mohdibrahimai/ARGOS))                        | Retriever â†’ Answer â†’ **Verify each sentence**, with inline citations, dashboards, and Helm deploys. | FastAPI, Next.js, Docker, Helm |
| **Prompt Contracts + Fuzzing CI for Answer Engines** ([old: HELMSMAN](https://github.com/mohdibrahimai/HELMSMAN)) | Turn prompts into **contracts**; run **packs**, diffs, and **CI gates** to block regressions.       | Python, YAML DSL               |
| **(Working Title) Proofâ€‘Carrying Answers** ([PALADIN](https://github.com/mohdibrahimai/PALADIN))                  | Produce answers **with minimal evidence graphs**; deterministic verifier checks support & hashes.   | Python                         |
| **Humanâ€‘Guided Parametricâ€‘vsâ€‘Retrieval Gating** ([old: JANUS](https://github.com/mohdibrahimai/JANUS))            | Perâ€‘query **route**: model memory vs **retrieve & cite** vs compute vs **clarify** vs **abstain**.  | Python, Policy Engine          |
| **Universal Intent Resolution Engine** ([UIRE](https://github.com/mohdibrahimai/UIRE))                            | Detect ambiguity â†’ microâ€‘clarify â†’ policyâ€‘based intent â†’ prompt construction.                       | FastAPI, Docker, Helm          |
| **TruthLens** ([HF Space](https://huggingface.co/spaces/afridi/TruthLens))                                        | Claim â†’ Evidence stance (support/contradict/neutral) with simple dashboards.                        | HF Spaces, Transformers        |

**More:** DataLoaderSpeedrun Â· BreezeMindâ€‘Pro Â· Career Vision AI Â· Humanâ€‘Feedbackâ€‘Safetyâ€‘Simulator â€” see GitHub â†’ Repos.

---

## ğŸ“ˆ Impact Highlights

* ğŸ“Š Hallucinations **âˆ’38%**, latency **âˆ’23%**, cost **âˆ’44%** across 5+ pipelines
* ğŸ† Factual F1 **+7â€“12pp**; Dâ€‘CoT RMs improved ArenaHard **+3.4pp**
* ğŸ“š Research artifacts: [Grokâ€‘3](https://zenodo.org/records/15227014), [Grokâ€‘3+](https://zenodo.org/records/15341810)
* ğŸ”§ Prompt contracts, nightly eval dashboards, and **safety gates** shipped

---

## ğŸ§  Tech Stack

**Languages:** Python, C++, TypeScript/JS
**Frameworks:** PyTorch, TensorFlow, JAX, FastAPI, Next.js
**Infra:** Docker, Kubernetes, Helm, Prometheus, Grafana
**Concepts:** MoE, FP8, RLHF, KV caching, LoRA, DQN
**Other:** Z3, Lean4, CI/CD, Retrieval, Eval pipelines

---

## ğŸ”’ AI Safety & Trust Principles

* Build **evidenceâ€‘bound** systems (claims must cite sources)
* Add **prompt contracts** + **CI gates** to catch regressions early
* Run **nightly evals** with safety & calibration metrics
* Prefer **abstain/route** over confident nonsense
* Ship **receipts**: versions, seeds, costs, checks for replayability

---

## ğŸ’Œ Letâ€™s Collaborate

If youâ€™re building **frontier models, eval frameworks, or safety tooling** â€” Iâ€™d love to collaborate. Letâ€™s make AI **safer, smarter, and actually trustworthy.** ğŸ›¡ï¸

> *â€œAI safety isnâ€™t a checkbox â€” itâ€™s a responsibility.â€* â€” me, probably during a caffeine high â˜•ğŸ˜„

---

## ğŸ“Š GitHub Stats

![Afridi's GitHub stats](https://github-readme-stats.vercel.app/api?username=mohdibrahimai\&show_icons=true\&theme=radical)

---

## ğŸ§© Fun Fact

I treat debugging like detective workâ€¦ except the culprit is **me** from 3 AM last night. ğŸ•µï¸â€â™‚ï¸
