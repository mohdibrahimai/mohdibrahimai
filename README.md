# ğŸ’» Mohd Ibrahim Afridi (Afridi)

**AI/ML Engineer â€¢ Independent Researcher â€¢ Entrepreneur â€¢ AI Safety & Trust**
[ğŸŒ Portfolio](https://mohdibrahimai.github.io/portfolio-/) Â· [ğŸ“§ Email](mailto:mohdibrahimafridi.ai@gmail.com) Â· [ğŸ’¼ LinkedIn](https://www.linkedin.com/in/mohd-ibrahim-afridi-381b12381) Â· [ğŸ™ GitHub](https://github.com/mohdibrahimai)

---

## ğŸš€ About Me

Hi, Iâ€™m Afridi â€” an AI/ML engineer and independent researcher obsessed with building **verifiable, trustworthy, safe AI systems**.

* ğŸ§  Founder & CTO at **XCL3NT**, an AI-first commerce brand
* ğŸ¤– Researcher behind **Dynamic Chain-of-Thought Reward Models (D-CoT)** â€” [Read D-CoT](https://zenodo.org/records/16554886)
* ğŸ›¡ï¸ Focus: **AI Safety & Trust** â€” designing systems with evidence, evaluation, and safeguards by default
* ğŸŒ Remote-ready and open to relocation (US/EU/NZ/SEA)

> *Mission: Make AI safer, more transparent, and actually helpful to humanity.* ğŸŒ±

---

## ğŸ§ª My Research Focus

* **AI Safety & Trust**: principled safeguards, red-teaming, abstain/route policies, and post-hoc verification
* Verifiable QA systems (answers backed by evidence)
* Model behavior analysis & safety alignment
* Evaluation frameworks (metrics, gates, nightly reports)
* Human-data pipelines (collection â†’ curation â†’ evals)
* Cost/freshness routing and retrieval-generation hybrids

---

## ğŸ› ï¸ Selected Projects

| Project                                                         | Description                                                  | Stack                          |
| --------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------ |
| [**ARGOS**](https://github.com/mohdibrahimai/ARGOS)             | Evidence-bound answer engine (retriever â†’ answer â†’ verifier) | FastAPI, Next.js, Docker, Helm |
| [**HELMSMAN**](https://github.com/mohdibrahimai/HELMSMAN)       | Prompt contracts + fuzzing CI framework                      | Python, YAML DSL               |
| [**PALADIN**](https://github.com/mohdibrahimai/PALADIN)         | Proof-carrying answers with evidence graphs                  | Python, Graph APIs             |
| [**UIRE**](https://github.com/mohdibrahimai/UIRE)               | Universal Intent Resolution Engine (handles ambiguity)       | FastAPI, Docker, Helm          |
| [**JANUS**](https://github.com/mohdibrahimai/JANUS)             | Freshness/cost-aware routing and gating                      | Python, Policy Engine          |
| [**TruthLens**](https://huggingface.co/spaces/afridi/TruthLens) | Claim â†’ Evidence fact-checking engine                        | HF Spaces, Transformers        |

> Plus: DataLoaderSpeedrun, BreezeMind-Pro, Career Vision AI, Human-Feedback-Safety-Simulator, and more on my GitHub.

---

## ğŸ“ˆ Impact Highlights

* ğŸ“Š Reduced hallucinations by **âˆ’38%**, latency by **âˆ’23%**, and cost by **âˆ’44%** across 5+ pipelines
* ğŸ† Boosted factual F1 by **+7â€“12pp** and alignment quality on ArenaHard by **+3.4pp** with D-CoT RMs
* ğŸ“š Published research like [Grok-3](https://zenodo.org/records/15227014) and [Grok-3+](https://zenodo.org/records/15341810)
* ğŸ§© Designed prompt contracts, nightly eval dashboards, and safety gates that scale

---

## ğŸ§  Tech Stack

**Languages:** Python, C++, TypeScript, JS
**Frameworks:** PyTorch, TensorFlow, JAX, FastAPI, Next.js
**Infra:** Docker, Kubernetes, Helm, Prometheus, Grafana
**Concepts:** MoE, FP8, RLHF, KV caching, LoRA, DQN
**Other:** Z3, Lean4, CI/CD, Retrieval, Eval pipelines

---

## ğŸ’Œ Letâ€™s Collaborate

If youâ€™re building **frontier models, eval frameworks, or safety tooling** â€” Iâ€™d love to collaborate.
Letâ€™s make AI **safer, smarter, and actually trustworthy.** ğŸ›¡ï¸

> *â€œAI safety isnâ€™t a checkbox â€” itâ€™s a responsibility.â€* â€“ Me, probably during a caffeine high â˜•ğŸ˜„

---

## ğŸ”’ AI Safety & Trust

* Build **evidence-bound** systems (claims must cite sources)
* Add **prompt contracts** + **CI gates** for regressions
* Use **nightly evals** with safety and calibration metrics
* Prefer **abstain/route** over confident nonsense
* Ship **receipts**: versions, seeds, costs, and checks for replayability

---

## ğŸ“Š GitHub Stats

![Afridi's GitHub stats](https://github-readme-stats.vercel.app/api?username=mohdibrahimai\&show_icons=true\&theme=radical)

---

## ğŸ§© Fun Fact

I treat debugging like detective workâ€¦ except the culprit is **me** from 3 AM last night. ğŸ•µï¸â€â™‚ï¸
