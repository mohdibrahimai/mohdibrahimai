# 💻 Mohd Ibrahim Afridi (Afridi)

**AI/ML Engineer • Independent Researcher • Entrepreneur • AI Safety & Trust**
[🌐 Portfolio](https://mohdibrahimai.github.io/portfolio-/) · [📧 Email](mailto:mohdibrahimafridi.ai@gmail.com) · [💼 LinkedIn](https://www.linkedin.com/in/mohd-ibrahim-afridi-381b12381) · [🐙 GitHub](https://github.com/mohdibrahimai)

---

## 🚀 About Me

Hi, I’m Afridi — an AI/ML engineer and independent researcher obsessed with building **verifiable, trustworthy, safe AI systems**.

* 🧠 Founder & CTO at **XCL3NT**, an AI-first commerce brand
* 🤖 Researcher behind **Dynamic Chain-of-Thought Reward Models (D-CoT)** — [Read D-CoT](https://zenodo.org/records/16554886)
* 🛡️ Focus: **AI Safety & Trust** — designing systems with evidence, evaluation, and safeguards by default
* 🌍 Remote-ready and open to relocation (US/EU/NZ/SEA)

> *Mission: Make AI safer, more transparent, and actually helpful to humanity.* 🌱

---

## 🧪 My Research Focus

* **AI Safety & Trust**: principled safeguards, red-teaming, abstain/route policies, post-hoc verification
* Verifiable QA systems (answers backed by evidence)
* Model behavior analysis & safety alignment
* Evaluation frameworks (metrics, gates, nightly reports)
* Human-data pipelines (collection → curation → evals)
* Cost/freshness routing and retrieval–generation hybrids

---

## 🛠️ Selected Projects (renamed)

| Project                                                                                                                                 | Description                                                                                             | Stack                          |
| --------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------ |
| [**Evidence‑Bound Answering System**](https://github.com/mohdibrahimai/Evidence-Bound-Answering-System)                                 | Evidence‑bound answering (retriever → answer → verifier) with inline citations & sentence‑level checks. | FastAPI, Next.js, Docker, Helm |
| [**Prompt Contracts + Fuzzing CI for Answer Engines**](https://github.com/mohdibrahimai/Prompt-Contracts-Fuzzing-CI-for-Answer-Engines) | Prompt‑contracts DSL, stress packs, evaluators, and **CI gates** to block regressions.                  | Python, YAML DSL               |
| [**Proof‑Answers**](https://github.com/mohdibrahimai/Proof-Answers-)                                                                    | Proof‑carrying answers with **minimal evidence graphs** + deterministic verifier and hash checks.       | Python, Graph/Verifier         |
| [**UIRE**](https://github.com/mohdibrahimai/UIRE)                                                                                       | Universal Intent Resolution Engine — ambiguity detection → micro‑clarifications → structured intents.   | FastAPI, Docker, Helm          |
| [**Human‑Guided Parametric‑vs‑Retrieval Gating**](https://github.com/mohdibrahimai/Human-Guided-Parametric-vs-Retrieval-Gating)         | Per‑query policy to **answer / retrieve / compute / clarify / abstain**; freshness‑ & cost‑aware.       | Python, Policy Engine          |
| [**TruthLens**](https://huggingface.co/spaces/afridi/TruthLens)                                                                         | Claim→Evidence stance (support/contradict/neutral) for fact‑checking.                                   | HF Spaces, Transformers        |

> **Name changes for clarity:** ARGOS → *Evidence‑Bound Answering System* · HELMSMAN → *Prompt Contracts + Fuzzing CI for Answer Engines* · PALADIN → *Proof‑Answers* · JANUS → *Human‑Guided Parametric‑vs‑Retrieval Gating*.

---

## 📈 Impact Highlights

* 📊 Reduced hallucinations **−38%**, latency **−23%**, and cost **−44%** across 5+ pipelines.
* 🏆 Improved factual F1 by **+7–12pp** and ArenaHard alignment **+3.4pp** with D‑CoT RMs.
* 📚 Published work: [Grok‑3](https://zenodo.org/records/15227014), [Grok‑3+](https://zenodo.org/records/15341810).
* 🧩 Designed prompt contracts, nightly eval dashboards, and safety gates that scale.

---

## 🧠 Tech Stack

**Languages:** Python, C++, TypeScript, JS
**Frameworks:** PyTorch, TensorFlow, JAX, FastAPI, Next.js
**Infra:** Docker, Kubernetes, Helm, Prometheus, Grafana
**Concepts:** MoE, FP8, RLHF, KV caching, LoRA, DQN
**Other:** Z3, Lean4, CI/CD, Retrieval, Eval pipelines

---

## 💌 Let’s Collaborate

If you’re building **frontier models, eval frameworks, or safety tooling** — I’d love to collaborate.
Let’s make AI **safer, smarter, and actually trustworthy.** 🛡️

> *“AI safety isn’t a checkbox — it’s a responsibility.”* – me (probably during a caffeine high ☕😄)

---

## 🔒 AI Safety & Trust Principles

* Build **evidence‑bound** systems (claims must cite sources).
* Add **prompt contracts** + **CI gates** for regressions.
* Use **nightly evals** with safety & calibration metrics.
* Prefer **abstain/route** over confident nonsense.
* Ship **receipts**: versions, seeds, costs, and checks for replayability.

---

## 📊 GitHub Stats

![Afridi's GitHub stats](https://github-readme-stats.vercel.app/api?username=mohdibrahimai\&show_icons=true\&theme=radical)

---

## 🧩 Fun Fact

I treat debugging like detective work… except the culprit is **me** from 3 AM last night. 🕵️‍♂️
