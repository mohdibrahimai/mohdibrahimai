# ğŸ’» Mohd Ibrahim Afridi (Afridi)

**AI/ML Engineer â€¢ Independent Researcher â€¢ Entrepreneur â€¢ AI Safety & Trust**
[ğŸŒ Portfolio](https://mohdibrahimai.github.io/portfolio-/) Â· [ğŸ“§ Email](mailto:mohdibrahimafridi.ai@gmail.com) Â· [ğŸ’¼ LinkedIn](https://www.linkedin.com/in/mohd-ibrahim-afridi-381b12381) Â· [ğŸ™ GitHub](https://github.com/mohdibrahimai)

---

## ğŸš€ About Me

Hi, Iâ€™m Afridi â€” an AI/ML engineer and independent researcher obsessed with building **verifiable, trustworthy, safe AI systems**.

* ğŸ§  Founder & CTO at **XCL3NT**, an AI-first commerce brand
* ğŸ¤– Researcher behind **Dynamic Chain-of-Thought Reward Models (D-CoT)** â€” [Read D-CoT](https://zenodo.org/records/16554886)
* ğŸ›¡ï¸ Focus: **AI Safety & Trust** â€” designing systems with evidence, evaluation, and safeguards by default
* ğŸŒ Remote-ready and open to relocation (US/EU/NZ/SEA)

> *Mission: Make AI safer, more transparent, and actually helpful to humanity.* ğŸŒ±

---

## ğŸ§ª My Research Focus

* **AI Safety & Trust**: principled safeguards, red-teaming, abstain/route policies, post-hoc verification
* Verifiable QA systems (answers backed by evidence)
* Model behavior analysis & safety alignment
* Evaluation frameworks (metrics, gates, nightly reports)
* Human-data pipelines (collection â†’ curation â†’ evals)
* Cost/freshness routing and retrievalâ€“generation hybrids

---

## ğŸ› ï¸ Selected Projects (renamed)

| Project                                                                                                                                 | Description                                                                                             | Stack                          |
| --------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- | ------------------------------ |
| [**Evidenceâ€‘Bound Answering System**](https://github.com/mohdibrahimai/Evidence-Bound-Answering-System)                                 | Evidenceâ€‘bound answering (retriever â†’ answer â†’ verifier) with inline citations & sentenceâ€‘level checks. | FastAPI, Next.js, Docker, Helm |
| [**Prompt Contracts + Fuzzing CI for Answer Engines**](https://github.com/mohdibrahimai/Prompt-Contracts-Fuzzing-CI-for-Answer-Engines) | Promptâ€‘contracts DSL, stress packs, evaluators, and **CI gates** to block regressions.                  | Python, YAML DSL               |
| [**Proofâ€‘Answers**](https://github.com/mohdibrahimai/Proof-Answers-)                                                                    | Proofâ€‘carrying answers with **minimal evidence graphs** + deterministic verifier and hash checks.       | Python, Graph/Verifier         |
| [**UIRE**](https://github.com/mohdibrahimai/UIRE)                                                                                       | Universal Intent Resolution Engine â€” ambiguity detection â†’ microâ€‘clarifications â†’ structured intents.   | FastAPI, Docker, Helm          |
| [**Humanâ€‘Guided Parametricâ€‘vsâ€‘Retrieval Gating**](https://github.com/mohdibrahimai/Human-Guided-Parametric-vs-Retrieval-Gating)         | Perâ€‘query policy to **answer / retrieve / compute / clarify / abstain**; freshnessâ€‘ & costâ€‘aware.       | Python, Policy Engine          |
| [**TruthLens**](https://huggingface.co/spaces/afridi/TruthLens)                                                                         | Claimâ†’Evidence stance (support/contradict/neutral) for factâ€‘checking.                                   | HF Spaces, Transformers        |

> **Name changes for clarity:** ARGOS â†’ *Evidenceâ€‘Bound Answering System* Â· HELMSMAN â†’ *Prompt Contracts + Fuzzing CI for Answer Engines* Â· PALADIN â†’ *Proofâ€‘Answers* Â· JANUS â†’ *Humanâ€‘Guided Parametricâ€‘vsâ€‘Retrieval Gating*.

---

## ğŸ“ˆ Impact Highlights

* ğŸ“Š Reduced hallucinations **âˆ’38%**, latency **âˆ’23%**, and cost **âˆ’44%** across 5+ pipelines.
* ğŸ† Improved factual F1 by **+7â€“12pp** and ArenaHard alignment **+3.4pp** with Dâ€‘CoT RMs.
* ğŸ“š Published work: [Grokâ€‘3](https://zenodo.org/records/15227014), [Grokâ€‘3+](https://zenodo.org/records/15341810).
* ğŸ§© Designed prompt contracts, nightly eval dashboards, and safety gates that scale.

---

## ğŸ§  Tech Stack

**Languages:** Python, C++, TypeScript, JS
**Frameworks:** PyTorch, TensorFlow, JAX, FastAPI, Next.js
**Infra:** Docker, Kubernetes, Helm, Prometheus, Grafana
**Concepts:** MoE, FP8, RLHF, KV caching, LoRA, DQN
**Other:** Z3, Lean4, CI/CD, Retrieval, Eval pipelines

---

## ğŸ’Œ Letâ€™s Collaborate

If youâ€™re building **frontier models, eval frameworks, or safety tooling** â€” Iâ€™d love to collaborate.
Letâ€™s make AI **safer, smarter, and actually trustworthy.** ğŸ›¡ï¸

> *â€œAI safety isnâ€™t a checkbox â€” itâ€™s a responsibility.â€* â€“ me (probably during a caffeine high â˜•ğŸ˜„)

---

## ğŸ”’ AI Safety & Trust Principles

* Build **evidenceâ€‘bound** systems (claims must cite sources).
* Add **prompt contracts** + **CI gates** for regressions.
* Use **nightly evals** with safety & calibration metrics.
* Prefer **abstain/route** over confident nonsense.
* Ship **receipts**: versions, seeds, costs, and checks for replayability.

---

## ğŸ“Š GitHub Stats

![Afridi's GitHub stats](https://github-readme-stats.vercel.app/api?username=mohdibrahimai\&show_icons=true\&theme=radical)

---

## ğŸ§© Fun Fact

I treat debugging like detective workâ€¦ except the culprit is **me** from 3 AM last night. ğŸ•µï¸â€â™‚ï¸
